{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45cddf8-6ec0-4afc-a675-67e0837527f8",
   "metadata": {},
   "source": [
    "## 신경망 학습\n",
    "* train data로부터 자동으로 weight를 최적의 값으로 자동으로 획득\n",
    "* 학습을 하려면\n",
    "    * loss function의 결과값을 가장 작게 만드는 weight를 찾아야한다.\n",
    "        * loss function을 찾는 방법 : 경사하강법\n",
    "* ex) 손글씨 5를 보고 -> 5를 분류하는 프로그램 => 알고리즘??\n",
    "    * 숨은 규칙성을 명확한 로직으로 풀기 어렵다.\n",
    "    * 기계학습 : 이미지에서 feature를 추출 (사람) -> vector (input data에서 중요한 data추출) -> classification(SVM,KNN)\n",
    "        * data로부터 규칙을 기계가 찾아낸다. 하지만 feature는 사람이 한다.\n",
    "    * 딥러닝 : 사람 개입x\n",
    "        * 이미지를 있는 그대로 학습 -> 특징까지 스스로 학습\n",
    "        * (end-to-end machine learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a419de-9a03-46d0-af51-85dcbe1d5b66",
   "metadata": {},
   "source": [
    "## data 취급의 주의점\n",
    "* in 기계학습\n",
    "    * train data & test data\n",
    "        * train data : 최적의 weight를 찾도록\n",
    "        * test data를 이용해서 generalization 확인 -> 성능이 엉망이라면 : overfitting (학습데이터에 과적합)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70426d8-3200-4fc8-a941-b4c93debf60f",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "* 신경망학습에서는 현재의 상태를 '하나의 지표'로 표현\n",
    "* 그 지표를 가장 좋게 만들어주는 weight 값을 선택한다.\n",
    "* loss function을 기준으로 최적의 weight 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402b334-0b15-47fa-ac75-0e053a75dfcf",
   "metadata": {},
   "source": [
    "### SSE (오차 제곱 합)\n",
    "* E  = 0.5 * np.sum((y-t)**2)\n",
    "    * y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "    * t = [0,0,1,0,0,0,0,0,0,0]\n",
    "    * E = 0.5 * (0.1^2 + 0.05^2 + 0.4^2 + 0.05^2 + 0.1^2 + 0.1^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7841280f-babf-42f2-a34d-46ec5efb2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f97515b0-cf45-4675-97a9-952784f1b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(y,t):\n",
    "    return -0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62942f52-bb6d-4622-b628-1634ea7eb882",
   "metadata": {},
   "source": [
    "### Cross-entropy-error\n",
    "* E = -np.sum(t*np.log(y))\n",
    "    * t = [0,0,1,0,0,0,0,0,0,0]\n",
    "    * y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "    * E = -log(0.6) = 0.51\n",
    "    * x가 1에 가까울 수록 y는 0에 가까워지는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6a7ce2-fad1-4df6-ada0-baf03371c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*log(y + delta))\n",
    "# delta : log(0) 일경우 -inf가 되어 계산을 못하기 때문에 작은 수 delta를 더해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb428bf-fdfc-460e-bf3b-d0dc68391ad3",
   "metadata": {},
   "source": [
    "## mini batch 학습\n",
    "* 최적의 weight updata를 위해선 모든 data에 대한 loss function을 알아야한다.\n",
    "* ex) Cross Entropy Error\n",
    "    * E = $\\frac {1}{N} \\Sigma_n \\Sigma_k t_{nk} log{y_{nk}}$\n",
    "    * data N개 -> row\n",
    "    * k번째에 정답 -> col 선택해서\n",
    "* train data 중에서 일부만 골라 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e60c196-7aeb-4c87-9887-f40f56c1f8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(X_train,t_train),(X_test,t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(t_train.shape)\n",
    "print(X_test.shape)\n",
    "print(t_test.shape)\n",
    "# 784 = 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0798655-e9bb-40ae-9c54-c4d3490729a4",
   "metadata": {},
   "source": [
    "## train data에서 무작위로 10장 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eee35f9-f3c1-4aa0-85e0-52e5431ff218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = X_train.shape[0] #60000\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) #60000중에서 무작위로 10개의 숫자 선택해서 list\n",
    "\n",
    "x_batch = X_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "print(x_batch.shape)\n",
    "print(t_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a51e13b-c1e4-40dc-bc61-b53a7571bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7840"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b329bff3-2d7e-48d0-a627-abbfdcb2fc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca1339-ae6f-477e-925b-adb4de7a08c7",
   "metadata": {},
   "source": [
    "#### 시청률도 전체를 조사하는 것이 아니라 경기지방에서 무작위로 1000가구를 선정해서 전체 시청률로 근사시킨다. 이와 비슷한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0b5c2-45d0-45a4-89d9-2b25014060b7",
   "metadata": {},
   "source": [
    "## batch용 Cross Entropy error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784b685-8ac2-4e57-a70e-d0ac99d63874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(1,y.size)\n",
    "        t = t.reshape(1,t.size) #입력된 데이터가 1차원일 경우 2차원으로 바꿔주는 함수\n",
    "        \n",
    "    batch_size = y.shape[0] #10\n",
    "    return -np.sum(t*np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be03e0ae-83fd-477b-8463-dc219ae88cad",
   "metadata": {},
   "source": [
    "## 왜 손실함수를 설정하는가?\n",
    "* 높은 정확도를 끌어내는 weight를 찾는 것\n",
    "* 손실함수의 값으로 정확도를 대신한다.\n",
    "    * 미분 : 최적의 weight를 탐색할 때 손실함의 값을 가능한 작게하는 weight를 찾는다.\n",
    "        * weight의 미분을 계산 -> 미분값을 이용해서 weight를 update하는 과정을 반복\n",
    "    * 미분 : 가중치의 매개변수값을 아주 조금 변화시켰을 때 손실함수가 얼마나 변하는지 알수 있다.\n",
    "* 정확도를 지표로 삼을 경우 : 매개변수를 조금 변화시켜도 정확도는 거의 변하지 않기 때문에 미분이 대부분의 장소에서 0이되기 때문에 학습을 할 수가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb0bdc-c0d8-4f4e-833d-3661625a19d3",
   "metadata": {},
   "source": [
    "## 손실함수를 사용하는 것과 비슷하게 Step function Vs Sigmoid\n",
    "* step function은 대부분의 장소에서 미분 = 0 -> 의미x\n",
    "    * why? weight의 작은 변화가 주는 파장을 step function이 없앤다.\n",
    "* But\n",
    "* Sigmoid는 연속적으로 변화 -> 곡선의 기울기도 연속적\n",
    "    * 어떤 곳이든 미분 != 0\n",
    "        * 신경망이 학습을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195e076-c5b9-4d40-bcec-8e9ad1bd764b",
   "metadata": {},
   "source": [
    "## 경사법 (Gradient Descent)\n",
    "* 최적의 매개변수(weight, bias)를 찾아야한다.\n",
    "    * loss가 최솟값일 때 매개변수\n",
    "* 기울기를 이용하여 찾기\n",
    "* But\n",
    "* 기울기가 가리키는 곳에 최솟값이 있는지 보장할수는 없다.\n",
    "    * 경사법은 기울기가 0인 장소를 찾지만, 0인 곳은 지역최소값일 수도 있고 안장점일 수도 있기 때문이다.\n",
    "* 기울어진 방향으로 일정거리($\\eta$)만큼 이동을 반복\n",
    "    * $x = x - \\frac {\\partial f} {\\partial x}$def Gradient(f,x):\n",
    "    h=1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x) # f(x+h) 계산\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x) # f(x-h) 계산\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / 2*h\n",
    "        x[idx] = tmp_val # 원상복구\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "829eb0c5-36aa-444a-9851-a4069c5bce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f,x):\n",
    "    h=1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x) # f(x+h) 계산\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x) # f(x-h) 계산\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 원상복구\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a64376a4-df09-4822-93e4-d4c4a549fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2 # == np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "047241ff-cd73-4f0a-b967-86b4158e3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b756b957-5f62-4f3b-a1e8-2f5a25747dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  4.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "init_x = np.array([-3.0,4.0])\n",
    "init_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3532d581-41ca-4e36-8a12-2418d346b011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2,np.array([0.0,2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56774830-1e7f-4e10-b409-2765156f2d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2,init_x=init_x,lr=0.1,step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db8276-a485-4d70-b60f-bb709378ea0a",
   "metadata": {},
   "source": [
    "## $\\eta$ (learning rate)\n",
    "* learning rate가 너무 크면 : 발산\n",
    "* learning rate가 너무 작으면 : 학습이 너무 오래걸린다. (epoch가 다 돌아도 최저점에 도달하지 못한다.)\n",
    "* 적절한 learning rate가 중요\n",
    "* $\\eta$와 같은 사람이 정해주는 파라미터를\n",
    "    * 하이퍼 파라미터라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e45332de-30c8-48dd-9fd0-3eca145b5eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2,init_x=init_x,lr=10.0,step_num=100)\n",
    "#학습률이 너무 크다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4a84a1f-f7e8-4569-8bc5-fcb1703f2772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0,4.0])\n",
    "gradient_descent(function_2,init_x=init_x,lr=1e-10,step_num=100)\n",
    "#학습률이 너무작다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52270121-8aa9-413e-8cea-0b06f7f45140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Six",
   "language": "python",
   "name": "six"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
